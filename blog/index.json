[{"content":"","date":"4 February 2026","externalUrl":null,"permalink":"/tracksy/blog/decisions/","section":"Decisions","summary":"","title":"Decisions","type":"decisions"},{"content":" Context and Problem Statement # We have introduced end-to-end tests to ensure application stability and reliability. E2E tests rely on static datasets generated at one moment. This may cause issues as the models need to evolve (as streaming providers evolve on their side).\nWe need to ensure the end-to-end tests are reproducible with the same data but agnostic to model changes while maintaining test reliability and consistency across different environments and time periods.\nKey challenges:\nE2E tests currently use a static ZIP file (streamings_1000.zip) with hardcoded assertions Model evolution requires dataset schema changes Different developers and CI environments must produce identical test results Test data must remain stable even when synthetic generation logic evolves Considered Options # Option 1: Frozen Static Dataset # Keep using pre-generated static datasets (current approach with streamings_1000.zip).\nPros:\nCompletely reproducible across all environments No dependency on synthetic generation logic Fast test execution (no generation overhead) Cons:\nCannot evolve with model changes without manual intervention Requires manual regeneration and version control of binary files Difficult to update when schema changes (regeneration changes the data) Option 2: Generated Dataset with Fixed Seed # Use the synthetic dataset generator with a fixed seed for E2E tests.\nPros:\nReproducible results across environments via seeding Automatically adapts to model schema changes Leverages existing synthetic generation infrastructure Can generate different dataset sizes as needed Version controlled generation logic instead of binary data Cons:\nRequires synthetic generation to run before/during tests Test reliability depends on generator stability Slightly slower test setup Need to ensure seed consistency across environments Option 3: Data-Agnostic E2E Tests # Write tests that don\u0026rsquo;t rely on specific data values but test functionality patterns.\nPros:\nMost flexible approach Immune to data variations Focus on application behavior rather than specific values Cons:\nCannot test specific edge cases or data scenarios Less thorough validation of data processing accuracy More complex test logic to handle dynamic assertions May miss data-specific bugs Less human readable test cases Decision Outcome # Chosen option: Generated Dataset with Fixed Seed, because it provides the best balance between reproducibility and maintainability while leveraging our existing synthetic generation infrastructure.\nJustification:\nTests can automatically adapt to model schema changes without manual intervention Maintains reproducibility across all environments and time periods Aligns with the project\u0026rsquo;s existing architecture and tooling Ensure synthetic-datasets evolves along side the application ","date":"4 February 2026","externalUrl":null,"permalink":"/tracksy/blog/decisions/reproductable-e2e-datasets/","section":"Decisions","summary":"Context and Problem Statement # We have introduced end-to-end tests to ensure application stability and reliability. E2E tests rely on static datasets generated at one moment. This may cause issues as the models need to evolve (as streaming providers evolve on their side).\n","title":"Reproducible E2E Datasets","type":"decisions"},{"content":"This blog aims to share insights, updates, and stories about Tracksy, our journey, and the broader tech landscape. Stay tuned for regular posts on various topics related to our work and interests!\n","date":"4 February 2026","externalUrl":null,"permalink":"/tracksy/blog/","section":"Welcome to Tracksy's blog ðŸŽ‰","summary":"This blog aims to share insights, updates, and stories about Tracksy, our journey, and the broader tech landscape. Stay tuned for regular posts on various topics related to our work and interests!\n","title":"Welcome to Tracksy's blog ðŸŽ‰","type":"page"},{"content":" Context and Problem Statement # Our monorepo contains three distinct applications using different technology stacks:\nWeb application: Astro / Node.js Synthetic datasets: Python / uv Blog: Golang / Hugo We currently lack a unified way to manage these projects. Developers often have to cd into specific directories to run commands (install, build, test). Furthermore, running tests or builds acts globally or manually, leading to inefficiencies (e.g., running all tests when only one app changed).\nWe need a tool that:\nUnifies management (one command to rule them all). Manages the lifecycle (install, test, build) across languages. Supports \u0026ldquo;smart\u0026rdquo; execution (caching, dependency graph analysis) to avoid running unnecessary tasks. Is simple, not over-engineered, and works \u0026ldquo;out-of-the-box\u0026rdquo; as much as possible. Considered Options # Moon (moonrepo): A build system and workspace tool designed for the modern web and polyglot repos. Native support for Node, Python, Go, and Rust. Mise (mise-en-place): A dev tool that combines environment management (like asdf) with a task runner. Simple and fast. Turborepo: High-performance build system for JavaScript/TypeScript monorepos. Can run other tasks but is JS-centric. Nx: A comprehensive build system with heavy plugin support for many languages. Just / Make: Simple command runners. Decision Outcome # Chosen option: Moon, because it offers the best balance of polyglot support, smart caching, and ease of use for our specific stack (Node, Python, Go).\nMoon vs. Mise: While Mise is an excellent tool for environment management and simple task running (meeting the \u0026ldquo;simple\u0026rdquo; criteria), it explicitly excludes \u0026ldquo;advanced task caching\u0026rdquo; and dependency graph analysis from its goals. Moon was selected because it provides the \u0026ldquo;smart execution\u0026rdquo; (running only affected tests) out-of-the-box via intelligent hashing, which is a critical requirement (\u0026ldquo;not run all tests\u0026rdquo;). Polyglot by Design: Unlike Turborepo (which is JS-first), Moon is built to handle multiple languages natively, making it easier to integrate our Python and Go projects without \u0026ldquo;hacking\u0026rdquo; package.json files or creating complex wrappers. Intelligent Caching: It provides the \u0026ldquo;not run all tests\u0026rdquo; requirement out-of-the-box by analyzing files and dependencies to only run what is affected. Toolchain Management: Moon can automatically manage and download the correct versions of Node, Python (and uv), and Go, ensuring a consistent environment for all developers (\u0026ldquo;lifecycle management\u0026rdquo;). Simplicity: It uses declarative YAML configuration which is easy to read and maintain compared to more complex setups like Nx. Consequences # Good: Developers can run commands like moon run :test from the root to test all affected projects, regardless of language. Good: CI times will decrease due to intelligent caching/hashing. Good: Environment consistency is guaranteed via toolchain management. Bad: Introduces a new tool to the stack that developers need to install (though it can be bootstrapped easily). More Information # Moon documentation Moon GitHub repository Turborepo documentation Mise-en-place documentation Nx documentation Just documentation ","date":"17 December 2025","externalUrl":null,"permalink":"/tracksy/blog/decisions/monorepo-management-tool/","section":"Decisions","summary":"Context and Problem Statement # Our monorepo contains three distinct applications using different technology stacks:\nWeb application: Astro / Node.js Synthetic datasets: Python / uv Blog: Golang / Hugo We currently lack a unified way to manage these projects. Developers often have to cd into specific directories to run commands (install, build, test). Furthermore, running tests or builds acts globally or manually, leading to inefficiencies (e.g., running all tests when only one app changed).\n","title":"Tooling for Monorepo Management","type":"decisions"},{"content":"","externalUrl":null,"permalink":"/tracksy/blog/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/tracksy/blog/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/tracksy/blog/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/tracksy/blog/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]